{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/hansonhoang/Library/Python/3.9/lib/python/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some resources\n",
    "#### https://shimat.github.io/opencvsharp_docs/html/6121915d-1174-7345-bdca-789ee1373642.htm\n",
    "#### https://www.geeksforgeeks.org/opencv-python-tutorial/?ref=shm \n",
    "#### https://www.geeksforgeeks.org/opencv-the-gunnar-farneback-optical-flow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Clips Up From The Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[355, 707, 1033, 1384, 1706, 2057, 2411, 2719, 3073, 3427, 3779, 4126, 4451, 4767, 5103, 5455, 5772, 6083, 6435, 6786, 7098, 7347, 7700, 7976, 7977, 8006, 8021, 8368, 8724, 9080, 9432]\n",
      "Starting Clip Extraction:\n",
      "Clip 1 has been saved to data/clips.\n",
      "Clip 2 has been saved to data/clips.\n",
      "Clip 3 has been saved to data/clips.\n",
      "Clip 4 has been saved to data/clips.\n",
      "Clip 5 has been saved to data/clips.\n",
      "Clip 6 has been saved to data/clips.\n",
      "Clip 7 has been saved to data/clips.\n",
      "Clip 8 has been saved to data/clips.\n",
      "Clip 9 has been saved to data/clips.\n",
      "Clip 10 has been saved to data/clips.\n",
      "Clip 11 has been saved to data/clips.\n",
      "Clip 12 has been saved to data/clips.\n",
      "Clip 13 has been saved to data/clips.\n",
      "Clip 14 has been saved to data/clips.\n",
      "Clip 15 has been saved to data/clips.\n",
      "Clip 16 has been saved to data/clips.\n",
      "Clip 17 has been saved to data/clips.\n",
      "Clip 18 has been saved to data/clips.\n",
      "Clip 19 has been saved to data/clips.\n",
      "Clip 20 has been saved to data/clips.\n",
      "Clip 21 has been saved to data/clips.\n",
      "Clip 22 has been saved to data/clips.\n",
      "Clip 23 has been saved to data/clips.\n",
      "Clip 24 has been saved to data/clips.\n",
      "Clip 25 has been saved to data/clips.\n",
      "Clip 26 has been saved to data/clips.\n",
      "Clip 27 has been saved to data/clips.\n",
      "Clip 28 has been saved to data/clips.\n",
      "Clip 29 has been saved to data/clips.\n",
      "Clip 30 has been saved to data/clips.\n",
      "Clip 31 has been saved to data/clips.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" purpose of this function is to crop the borders equally on both sides. Tested \n",
    "different border_ratio param values and found that 0.343 best suited for \n",
    "the the compilations videos in the dataset.\"\"\"\n",
    "def crop_borders(frame, border_ratio = 0.343):\n",
    "    height, width, _ = frame.shape\n",
    "    crop_width = int(width * border_ratio)\n",
    "    cropped_frame = frame[:, crop_width:-crop_width]  \n",
    "    return cropped_frame\n",
    "\n",
    "\"\"\" turns compilation into frames and compares the pixel intensities for frames after\n",
    "turning it to grayscale in consecutive order and if it is greater than a certain threshold, \n",
    "func will classify it as a scene change.  \n",
    "\"\"\"\n",
    "def detect_scenes(video_path, threshold):\n",
    "    # initialization\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    scene_changes = []\n",
    "    last_frame = None\n",
    "    frame_index = 0\n",
    "\n",
    "    # handling error if vid can't be opened\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Can't open video at {video_path}\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        cropped_frame = crop_borders(frame)\n",
    "\n",
    "        # convert to BGR, less compute + easy processing pixels\n",
    "        gray_frame = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # compares pixel intensity btwn frames if last frame is present, retrieves diff in values\n",
    "        if last_frame is not None:\n",
    "            diff = cv2.absdiff(gray_frame, last_frame)\n",
    "            mean_diff = diff.mean()\n",
    "\n",
    "            if mean_diff > threshold:\n",
    "                scene_changes.append(frame_index)\n",
    "\n",
    "        last_frame = gray_frame\n",
    "        frame_index += 1\n",
    "\n",
    "    # avoid cv error\n",
    "    cap.release()\n",
    "    return scene_changes\n",
    "\n",
    "\"\"\" takes in previous helper functions: crop_borders & detect_scenes. extracts clips with the side\n",
    "borders cropped out instead of having to manually go into the vid to clip them out. \"\"\"\n",
    "def extract_clips(video_path, scene_changes, output_dir, border_ratio = 0.343):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # handling error if vid can't be opened\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Can't open video at {video_path}\")\n",
    "        return\n",
    "\n",
    "    # encode vid + retrieve dims\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    crop_width = int(width * border_ratio)\n",
    "       \n",
    "    output_width = width - 2 * crop_width\n",
    "    output_height = height\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # append last frame to ensure the final clip is extracted bc detect_scene doesn't account for it\n",
    "    scene_changes.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "    print(\"Starting Clip Extraction:\")\n",
    "    for i in range(len(scene_changes) - 1):\n",
    "        # initialize start and end times based on detect_scenes)\n",
    "        start_frame = scene_changes[i]\n",
    "        end_frame = scene_changes[i + 1]\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clip_{i + 1}.mp4\")\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (output_width, output_height))\n",
    "\n",
    "        #record\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "        for frame_index in range(start_frame, end_frame):\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            cropped_frame = crop_borders(frame, border_ratio)\n",
    "            out.write(cropped_frame)\n",
    "\n",
    "        out.release()\n",
    "        print(f\"Clip {i+1} has been saved to {output_dir}.\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"data/YouTube.mp4\"  \n",
    "    output_dir = \"data/clips\"  \n",
    "\n",
    "    #tested these values and found that these params were\n",
    "    # best suited for threshold and border_ratio\n",
    "    # most likely threshold can be altered depending on the compilation\n",
    "    # video we're working with but highly unlikely, border_ratio is set          \n",
    "    threshold = 51                 \n",
    "    border_ratio = 0.343              \n",
    "\n",
    "    scene_changes = detect_scenes(video_path, threshold)\n",
    "    print(scene_changes)\n",
    "    extract_clips(video_path, scene_changes, output_dir, border_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping Clips Outside of Average Clip Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open data/clips/.DS_Store, skipping.\n",
      "Average clip duration: 10.41 seconds\n",
      "Removing clips shorter than 8.41 seconds\n",
      "Deleted data/clips/clip_26.mp4 (Duration: 0.50 sec)\n",
      "Deleted data/clips/clip_24.mp4 (Duration: 0.03 sec)\n",
      "Deleted data/clips/clip_31.mp4 (Duration: 19.99 sec)\n",
      "Deleted data/clips/clip_25.mp4 (Duration: 0.97 sec)\n",
      "Deleted data/clips/clip_21.mp4 (Duration: 8.31 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"data/clips/.DS_Store\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\"\"\" Purpose of function is to filter out clips within a time (seconds) deviation based on the average\n",
    "clip length within the folder. This will remove clips whose pixel intensities are so high that the previous\n",
    "helper functions continually clip it frame by frame and also the ending credits clip at the end of the video. \n",
    "Clips average time length will be calculated and a (arbitrary) deviation will be applied to the mean time length\n",
    "and delete videos outside of that frame. \n",
    "FEEL FREE TO ALTER DEVIATION IF IT DOESN'T SUIT CLIPS AFTER MANUALLY INSPECTING \"\"\"\n",
    "# i.e. arbitrary val of 2 based on the \"call my slimes\" tiktok dance\n",
    "def filtering_clips(output_dir, fps, deviation=2):\n",
    "    clip_durations = []\n",
    "    clip_paths = []\n",
    "\n",
    "    for clip_name in os.listdir(output_dir):\n",
    "        clip_path = os.path.join(output_dir, clip_name)\n",
    "        \n",
    "        cap = cv2.VideoCapture(clip_path)\n",
    "\n",
    "        # handling error if vid can't be opened \n",
    "        if not cap.isOpened():\n",
    "            print(f\"Could not open {clip_path}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = frame_count / fps  \n",
    "\n",
    "        clip_durations.append(duration)\n",
    "        clip_paths.append(clip_path)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    # when no clip vid lens are found\n",
    "    if len(clip_durations) == 0:\n",
    "        print(\"No valid clips found.\")\n",
    "        return\n",
    "\n",
    "    average_duration = sum(clip_durations) / len(clip_durations)\n",
    "\n",
    "    min_duration = max(0, average_duration - deviation)\n",
    "    max_duration = average_duration + deviation\n",
    "    print(f\"Average clip duration: {average_duration:.2f} seconds\")\n",
    "    print(f\"Removing clips shorter than {min_duration:.2f} seconds\")\n",
    "\n",
    "    for clip_path, duration in zip(clip_paths, clip_durations):\n",
    "        # removes those outside of the deviation range of the avg\n",
    "        # i.e. within 2 seconds of the average\n",
    "        if duration < min_duration or duration > max_duration:\n",
    "            os.remove(clip_path)\n",
    "            print(f\"Deleted {clip_path} (Duration: {duration:.2f} sec)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"data/YouTube.mp4\"  \n",
    "    output_dir = \"data/clips\"            \n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    filtering_clips(output_dir, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DensePose?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
