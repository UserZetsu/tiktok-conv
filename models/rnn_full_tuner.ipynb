{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(69)\n",
    "tf.random.set_seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sequential data\n",
    "def load_sequential_data(folders):\n",
    "    \"\"\" load csvs as sequences removing the frame column and discarding the first 90 rows of each file \"\"\"\n",
    "    data, labels = [], []\n",
    "\n",
    "    for folder, _ in folders:\n",
    "        if os.path.exists(folder):\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith('.csv'):\n",
    "                    file_path = os.path.join(folder, file)\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # remove first 90\n",
    "                    df = df.iloc[90:]\n",
    "\n",
    "                    # remove frame and label\n",
    "                    label = df.iloc[0, 0] \n",
    "                    features = df.iloc[:, 2:].values\n",
    "                    \n",
    "                    data.append(features)\n",
    "                    labels.append(label)\n",
    "        else:\n",
    "            print(f\"warning: folder {folder} not found.\")\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training folders\n",
    "train_folders = [\n",
    "    ('../rat_dance_csv/train', 1),\n",
    "    ('../neg_control_csv/train', 0)\n",
    "]\n",
    "\n",
    "# load dataset\n",
    "X, y = load_sequential_data(train_folders)\n",
    "\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "X = np.array([scaler.fit_transform(sample) for sample in X])  # normalize each sequence separately\n",
    "\n",
    "# shuffle dataset\n",
    "indices = np.random.permutation(len(X))\n",
    "X, y = X[indices], y[indices]\n",
    "\n",
    "# reshape X for RNN samples, timesteps, features\n",
    "timesteps, features = X.shape[1], X.shape[2]\n",
    "X = X.reshape(len(X), timesteps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a simplified rnn model\n",
    "def build_simple_rnn():\n",
    "    model = keras.Sequential([\n",
    "        # single bidirectional lstm layer\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(\n",
    "            units=64,  \n",
    "            return_sequences=False,\n",
    "            recurrent_dropout=0.2,\n",
    "            input_shape=(timesteps, features),\n",
    "        )),\n",
    "        keras.layers.Dropout(0.4),\n",
    "\n",
    "        # fully connected dense layer\n",
    "        keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "\n",
    "        # output layer\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "\n",
    "    # compile model with fixed learning rate\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4375 - loss: 1.9823 - val_accuracy: 0.3750 - val_loss: 1.6201 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.4062 - loss: 2.0476 - val_accuracy: 0.3750 - val_loss: 1.6186 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.4688 - loss: 1.8661 - val_accuracy: 0.3750 - val_loss: 1.6171 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.4062 - loss: 1.8689 - val_accuracy: 0.3750 - val_loss: 1.6155 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5000 - loss: 1.7033 - val_accuracy: 0.3750 - val_loss: 1.6141 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.4375 - loss: 1.8811 - val_accuracy: 0.3750 - val_loss: 1.6127 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.4688 - loss: 1.9109 - val_accuracy: 0.3750 - val_loss: 1.6114 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.4375 - loss: 1.8465 - val_accuracy: 0.3750 - val_loss: 1.6100 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6250 - loss: 1.7261 - val_accuracy: 0.3750 - val_loss: 1.6087 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.6562 - loss: 1.5448 - val_accuracy: 0.3750 - val_loss: 1.6072 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5625 - loss: 1.6374 - val_accuracy: 0.3750 - val_loss: 1.6058 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5938 - loss: 1.7271 - val_accuracy: 0.3750 - val_loss: 1.6043 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6250 - loss: 1.5660 - val_accuracy: 0.3750 - val_loss: 1.6029 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6250 - loss: 1.7291 - val_accuracy: 0.3750 - val_loss: 1.6014 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5625 - loss: 1.6601 - val_accuracy: 0.3750 - val_loss: 1.6000 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5312 - loss: 1.7205 - val_accuracy: 0.3750 - val_loss: 1.5986 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6875 - loss: 1.5108 - val_accuracy: 0.3750 - val_loss: 1.5973 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5000 - loss: 1.7427 - val_accuracy: 0.3750 - val_loss: 1.5960 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.6250 - loss: 1.5903 - val_accuracy: 0.3750 - val_loss: 1.5948 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5000 - loss: 1.7690 - val_accuracy: 0.3750 - val_loss: 1.5935 - learning_rate: 1.0000e-04\n",
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4062 - loss: 2.2532 - val_accuracy: 0.6250 - val_loss: 1.4720 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.4062 - loss: 1.9128 - val_accuracy: 0.6250 - val_loss: 1.4711 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6562 - loss: 1.7705 - val_accuracy: 0.6250 - val_loss: 1.4701 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.5312 - loss: 1.7483 - val_accuracy: 0.6250 - val_loss: 1.4693 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5625 - loss: 1.6589 - val_accuracy: 0.6250 - val_loss: 1.4683 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4688 - loss: 1.7798 - val_accuracy: 0.6250 - val_loss: 1.4674 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5938 - loss: 1.7494 - val_accuracy: 0.6250 - val_loss: 1.4664 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.5312 - loss: 1.8845 - val_accuracy: 0.6250 - val_loss: 1.4654 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.4375 - loss: 1.7000 - val_accuracy: 0.6250 - val_loss: 1.4643 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.4688 - loss: 1.7870 - val_accuracy: 0.6250 - val_loss: 1.4633 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5938 - loss: 1.7412 - val_accuracy: 0.6250 - val_loss: 1.4623 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5312 - loss: 1.8027 - val_accuracy: 0.6250 - val_loss: 1.4612 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4688 - loss: 1.6833 - val_accuracy: 0.6250 - val_loss: 1.4603 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6250 - loss: 1.6512 - val_accuracy: 0.6250 - val_loss: 1.4592 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4688 - loss: 1.7961 - val_accuracy: 0.6250 - val_loss: 1.4582 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5938 - loss: 1.5359 - val_accuracy: 0.6250 - val_loss: 1.4573 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.4375 - loss: 1.9159 - val_accuracy: 0.6250 - val_loss: 1.4566 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5312 - loss: 1.6789 - val_accuracy: 0.6250 - val_loss: 1.4559 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.5312 - loss: 1.5701 - val_accuracy: 0.6250 - val_loss: 1.4551 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5625 - loss: 1.6075 - val_accuracy: 0.6250 - val_loss: 1.4544 - learning_rate: 1.0000e-04\n",
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 1.9536 - val_accuracy: 0.3750 - val_loss: 1.5165 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.4688 - loss: 1.7526 - val_accuracy: 0.3750 - val_loss: 1.5151 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5312 - loss: 1.8162 - val_accuracy: 0.3750 - val_loss: 1.5137 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5000 - loss: 1.7770 - val_accuracy: 0.3750 - val_loss: 1.5124 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5312 - loss: 1.8226 - val_accuracy: 0.3750 - val_loss: 1.5111 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5938 - loss: 1.7637 - val_accuracy: 0.5000 - val_loss: 1.5098 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3750 - loss: 1.8459 - val_accuracy: 0.5000 - val_loss: 1.5085 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.4688 - loss: 1.9420 - val_accuracy: 0.5000 - val_loss: 1.5073 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.4688 - loss: 1.9369 - val_accuracy: 0.5000 - val_loss: 1.5060 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.4688 - loss: 1.7492 - val_accuracy: 0.5000 - val_loss: 1.5046 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5312 - loss: 1.7121 - val_accuracy: 0.5000 - val_loss: 1.5034 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.4375 - loss: 2.0918 - val_accuracy: 0.5000 - val_loss: 1.5021 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.4688 - loss: 1.6764 - val_accuracy: 0.5000 - val_loss: 1.5007 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5938 - loss: 1.6188 - val_accuracy: 0.5000 - val_loss: 1.4993 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.4062 - loss: 1.8344 - val_accuracy: 0.6250 - val_loss: 1.4979 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5312 - loss: 1.8118 - val_accuracy: 0.6250 - val_loss: 1.4966 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.4375 - loss: 2.0811 - val_accuracy: 0.6250 - val_loss: 1.4952 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7188 - loss: 1.5186 - val_accuracy: 0.6250 - val_loss: 1.4938 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6562 - loss: 1.5104 - val_accuracy: 0.6250 - val_loss: 1.4924 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6250 - loss: 1.5390 - val_accuracy: 0.6250 - val_loss: 1.4910 - learning_rate: 1.0000e-04\n",
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5938 - loss: 1.6304 - val_accuracy: 0.5000 - val_loss: 1.5313 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5000 - loss: 1.8423 - val_accuracy: 0.5000 - val_loss: 1.5297 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.4375 - loss: 1.9181 - val_accuracy: 0.5000 - val_loss: 1.5280 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5625 - loss: 1.5046 - val_accuracy: 0.5000 - val_loss: 1.5261 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5625 - loss: 1.6618 - val_accuracy: 0.5000 - val_loss: 1.5241 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5312 - loss: 1.7119 - val_accuracy: 0.5000 - val_loss: 1.5221 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6562 - loss: 1.6166 - val_accuracy: 0.5000 - val_loss: 1.5201 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5625 - loss: 1.6953 - val_accuracy: 0.6250 - val_loss: 1.5181 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5938 - loss: 1.7094 - val_accuracy: 0.6250 - val_loss: 1.5163 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5000 - loss: 1.7684 - val_accuracy: 0.6250 - val_loss: 1.5145 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5938 - loss: 1.6122 - val_accuracy: 0.6250 - val_loss: 1.5127 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7812 - loss: 1.3945 - val_accuracy: 0.6250 - val_loss: 1.5109 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5625 - loss: 1.6964 - val_accuracy: 0.6250 - val_loss: 1.5091 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5312 - loss: 1.7660 - val_accuracy: 0.6250 - val_loss: 1.5073 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6562 - loss: 1.5601 - val_accuracy: 0.6250 - val_loss: 1.5055 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6250 - loss: 1.5742 - val_accuracy: 0.6250 - val_loss: 1.5036 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7188 - loss: 1.5506 - val_accuracy: 0.6250 - val_loss: 1.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6562 - loss: 1.5504 - val_accuracy: 0.6250 - val_loss: 1.4997 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6875 - loss: 1.4302 - val_accuracy: 0.6250 - val_loss: 1.4978 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.4688 - loss: 1.7603 - val_accuracy: 0.6250 - val_loss: 1.4961 - learning_rate: 1.0000e-04\n",
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 1.7706 - val_accuracy: 0.5000 - val_loss: 1.5959 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.4062 - loss: 1.9255 - val_accuracy: 0.5000 - val_loss: 1.5939 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.4688 - loss: 2.1570 - val_accuracy: 0.5000 - val_loss: 1.5920 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.4062 - loss: 2.0397 - val_accuracy: 0.5000 - val_loss: 1.5903 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.3438 - loss: 2.3177 - val_accuracy: 0.5000 - val_loss: 1.5884 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5312 - loss: 1.9170 - val_accuracy: 0.5000 - val_loss: 1.5867 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5625 - loss: 1.6805 - val_accuracy: 0.5000 - val_loss: 1.5850 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.4688 - loss: 1.7169 - val_accuracy: 0.6250 - val_loss: 1.5831 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.4688 - loss: 1.9894 - val_accuracy: 0.6250 - val_loss: 1.5813 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.4688 - loss: 1.8492 - val_accuracy: 0.6250 - val_loss: 1.5795 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5000 - loss: 1.7706 - val_accuracy: 0.6250 - val_loss: 1.5778 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5625 - loss: 1.8764 - val_accuracy: 0.6250 - val_loss: 1.5760 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3750 - loss: 2.0401 - val_accuracy: 0.6250 - val_loss: 1.5743 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5625 - loss: 1.6785 - val_accuracy: 0.6250 - val_loss: 1.5727 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5000 - loss: 1.7437 - val_accuracy: 0.6250 - val_loss: 1.5711 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4688 - loss: 1.9236 - val_accuracy: 0.6250 - val_loss: 1.5693 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5625 - loss: 1.7298 - val_accuracy: 0.6250 - val_loss: 1.5677 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.5625 - loss: 1.7437 - val_accuracy: 0.6250 - val_loss: 1.5659 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5000 - loss: 1.6612 - val_accuracy: 0.6250 - val_loss: 1.5643 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5312 - loss: 1.9458 - val_accuracy: 0.6250 - val_loss: 1.5628 - learning_rate: 1.0000e-04\n",
      "cross-validation accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=69)\n",
    "cv_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # build model\n",
    "    model = build_simple_rnn()\n",
    "\n",
    "    # define callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "    )\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    model.fit(\n",
    "        X_train, y_train, epochs=20, batch_size=32, verbose=1,\n",
    "        validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    cv_accuracies.append(val_acc)\n",
    "\n",
    "# print cross-validation accuracy\n",
    "cross_val_acc = np.mean(cv_accuracies)\n",
    "print(f\"cross-validation accuracy: {cross_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.4354 - loss: 2.0202 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.3438 - loss: 1.9103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.3646 - loss: 1.9429 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5708 - loss: 1.7232 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5542 - loss: 1.7244 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5917 - loss: 1.7651 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.4021 - loss: 1.8266 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5375 - loss: 1.7183 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5813 - loss: 1.7343 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5917 - loss: 1.7391 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5479 - loss: 1.7506 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6083 - loss: 1.5243 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5437 - loss: 1.7063 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6792 - loss: 1.5019 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5875 - loss: 1.6804 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6521 - loss: 1.5146 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.4625 - loss: 1.9700 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6250 - loss: 1.7285 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5167 - loss: 1.7340 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6521 - loss: 1.5243 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.6083 - loss: 1.6615 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x454503b50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train final model on full dataset\n",
    "final_model = build_simple_rnn()\n",
    "\n",
    "# train with early stopping\n",
    "final_model.fit(\n",
    "    X, y, epochs=20, batch_size=32, verbose=1, callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
      "\n",
      "validation performance:\n",
      "accuracy: 0.5714\n",
      "\n",
      "classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "negative control (0)       0.67      0.29      0.40         7\n",
      "        ratdance (1)       0.55      0.86      0.67         7\n",
      "\n",
      "            accuracy                           0.57        14\n",
      "           macro avg       0.61      0.57      0.53        14\n",
      "        weighted avg       0.61      0.57      0.53        14\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2 5]\n",
      " [1 6]]\n"
     ]
    }
   ],
   "source": [
    "# load validation dataset\n",
    "val_folders = [\n",
    "    ('../rat_dance_csv/val', 1),\n",
    "    ('../neg_control_csv/val', 0)\n",
    "]\n",
    "\n",
    "X_val, y_val = load_sequential_data(val_folders)\n",
    "X_val = np.array([scaler.transform(sample) for sample in X_val])  \n",
    "X_val = X_val.reshape(len(X_val), timesteps, features)  \n",
    "\n",
    "# evaluate on validation set\n",
    "y_pred_prob = final_model.predict(X_val)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "class_report = classification_report(y_val, y_pred, target_names=[\"negative control (0)\", \"ratdance (1)\"])\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# show results\n",
    "print(f\"\\nvalidation performance:\")\n",
    "print(f\"accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nclassification report:\")\n",
    "print(class_report)\n",
    "print(\"\\nconfusion matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "validation performance:\n",
      "accuracy: 0.6429\n",
      "\n",
      "classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "negative control (0)       1.00      0.29      0.44         7\n",
      "        ratdance (1)       0.58      1.00      0.74         7\n",
      "\n",
      "            accuracy                           0.64        14\n",
      "           macro avg       0.79      0.64      0.59        14\n",
      "        weighted avg       0.79      0.64      0.59        14\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2 5]\n",
      " [0 7]]\n"
     ]
    }
   ],
   "source": [
    "# load validation dataset\n",
    "test_folders = [\n",
    "    ('../rat_dance_csv/test', 1),\n",
    "    ('../neg_control_csv/test', 0)\n",
    "]\n",
    "\n",
    "X_test, y_test = load_sequential_data(test_folders)\n",
    "X_test = np.array([scaler.transform(sample) for sample in X_test])  \n",
    "X_test = X_test.reshape(len(X_test), timesteps, features)  \n",
    "\n",
    "# evaluate on validation set\n",
    "y_pred_prob = final_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=[\"negative control (0)\", \"ratdance (1)\"])\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# show results\n",
    "print(f\"\\nvalidation performance:\")\n",
    "print(f\"accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nclassification report:\")\n",
    "print(class_report)\n",
    "print(\"\\nconfusion matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
