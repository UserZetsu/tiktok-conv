{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/hansonhoang/Library/Python/3.9/lib/python/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some resources\n",
    "#### https://shimat.github.io/opencvsharp_docs/html/6121915d-1174-7345-bdca-789ee1373642.htm\n",
    "#### https://www.geeksforgeeks.org/opencv-python-tutorial/?ref=shm \n",
    "#### https://www.geeksforgeeks.org/opencv-the-gunnar-farneback-optical-flow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Clips Up From The Video + CLIP EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[447, 894, 1028, 1095, 1162, 1227, 1585, 1590, 1591, 1593, 1594, 1722, 2067, 2076, 2077, 2210, 2658, 2681, 2698, 2716, 3559, 4007, 4790, 5238, 6006, 6295, 6742, 7189, 7637, 8335, 8783, 9202, 9649, 9672, 9693, 9705, 9910, 10324, 10729, 10855, 11063, 11137, 11367, 11712, 12126, 12573, 13142, 13556, 14003, 14289, 14360, 14632, 15080, 15527, 15666, 15727, 15795, 15885, 16267, 16281, 16672, 17264, 17314, 17420, 17712, 18179, 18508, 18941, 19388, 19408, 19424, 19441, 19589, 19621, 19818, 20266, 20714, 21161, 21608, 22055, 22124, 22190, 22319, 22385, 22831, 23281, 23345, 23671, 23729, 24176]\n",
      "Starting Clip Extraction:\n",
      "Clip 1 has been saved to ratdance/clips.\n",
      "Clip 2 has been saved to ratdance/clips.\n",
      "Clip 3 has been saved to ratdance/clips.\n",
      "Clip 4 has been saved to ratdance/clips.\n",
      "Clip 5 has been saved to ratdance/clips.\n",
      "Clip 6 has been saved to ratdance/clips.\n",
      "Clip 7 has been saved to ratdance/clips.\n",
      "Clip 8 has been saved to ratdance/clips.\n",
      "Clip 9 has been saved to ratdance/clips.\n",
      "Clip 10 has been saved to ratdance/clips.\n",
      "Clip 11 has been saved to ratdance/clips.\n",
      "Clip 12 has been saved to ratdance/clips.\n",
      "Clip 13 has been saved to ratdance/clips.\n",
      "Clip 14 has been saved to ratdance/clips.\n",
      "Clip 15 has been saved to ratdance/clips.\n",
      "Clip 16 has been saved to ratdance/clips.\n",
      "Clip 17 has been saved to ratdance/clips.\n",
      "Clip 18 has been saved to ratdance/clips.\n",
      "Clip 19 has been saved to ratdance/clips.\n",
      "Clip 20 has been saved to ratdance/clips.\n",
      "Clip 21 has been saved to ratdance/clips.\n",
      "Clip 22 has been saved to ratdance/clips.\n",
      "Clip 23 has been saved to ratdance/clips.\n",
      "Clip 24 has been saved to ratdance/clips.\n",
      "Clip 25 has been saved to ratdance/clips.\n",
      "Clip 26 has been saved to ratdance/clips.\n",
      "Clip 27 has been saved to ratdance/clips.\n",
      "Clip 28 has been saved to ratdance/clips.\n",
      "Clip 29 has been saved to ratdance/clips.\n",
      "Clip 30 has been saved to ratdance/clips.\n",
      "Clip 31 has been saved to ratdance/clips.\n",
      "Clip 32 has been saved to ratdance/clips.\n",
      "Clip 33 has been saved to ratdance/clips.\n",
      "Clip 34 has been saved to ratdance/clips.\n",
      "Clip 35 has been saved to ratdance/clips.\n",
      "Clip 36 has been saved to ratdance/clips.\n",
      "Clip 37 has been saved to ratdance/clips.\n",
      "Clip 38 has been saved to ratdance/clips.\n",
      "Clip 39 has been saved to ratdance/clips.\n",
      "Clip 40 has been saved to ratdance/clips.\n",
      "Clip 41 has been saved to ratdance/clips.\n",
      "Clip 42 has been saved to ratdance/clips.\n",
      "Clip 43 has been saved to ratdance/clips.\n",
      "Clip 44 has been saved to ratdance/clips.\n",
      "Clip 45 has been saved to ratdance/clips.\n",
      "Clip 46 has been saved to ratdance/clips.\n",
      "Clip 47 has been saved to ratdance/clips.\n",
      "Clip 48 has been saved to ratdance/clips.\n",
      "Clip 49 has been saved to ratdance/clips.\n",
      "Clip 50 has been saved to ratdance/clips.\n",
      "Clip 51 has been saved to ratdance/clips.\n",
      "Clip 52 has been saved to ratdance/clips.\n",
      "Clip 53 has been saved to ratdance/clips.\n",
      "Clip 54 has been saved to ratdance/clips.\n",
      "Clip 55 has been saved to ratdance/clips.\n",
      "Clip 56 has been saved to ratdance/clips.\n",
      "Clip 57 has been saved to ratdance/clips.\n",
      "Clip 58 has been saved to ratdance/clips.\n",
      "Clip 59 has been saved to ratdance/clips.\n",
      "Clip 60 has been saved to ratdance/clips.\n",
      "Clip 61 has been saved to ratdance/clips.\n",
      "Clip 62 has been saved to ratdance/clips.\n",
      "Clip 63 has been saved to ratdance/clips.\n",
      "Clip 64 has been saved to ratdance/clips.\n",
      "Clip 65 has been saved to ratdance/clips.\n",
      "Clip 66 has been saved to ratdance/clips.\n",
      "Clip 67 has been saved to ratdance/clips.\n",
      "Clip 68 has been saved to ratdance/clips.\n",
      "Clip 69 has been saved to ratdance/clips.\n",
      "Clip 70 has been saved to ratdance/clips.\n",
      "Clip 71 has been saved to ratdance/clips.\n",
      "Clip 72 has been saved to ratdance/clips.\n",
      "Clip 73 has been saved to ratdance/clips.\n",
      "Clip 74 has been saved to ratdance/clips.\n",
      "Clip 75 has been saved to ratdance/clips.\n",
      "Clip 76 has been saved to ratdance/clips.\n",
      "Clip 77 has been saved to ratdance/clips.\n",
      "Clip 78 has been saved to ratdance/clips.\n",
      "Clip 79 has been saved to ratdance/clips.\n",
      "Clip 80 has been saved to ratdance/clips.\n",
      "Clip 81 has been saved to ratdance/clips.\n",
      "Clip 82 has been saved to ratdance/clips.\n",
      "Clip 83 has been saved to ratdance/clips.\n",
      "Clip 84 has been saved to ratdance/clips.\n",
      "Clip 85 has been saved to ratdance/clips.\n",
      "Clip 86 has been saved to ratdance/clips.\n",
      "Clip 87 has been saved to ratdance/clips.\n",
      "Clip 88 has been saved to ratdance/clips.\n",
      "Clip 89 has been saved to ratdance/clips.\n",
      "Clip 90 has been saved to ratdance/clips.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" purpose of this function is to crop the borders equally on both sides. Tested \n",
    "different border_ratio param values and found that 0.343 best suited for \n",
    "the the compilations videos in the dataset.\"\"\"\n",
    "def crop_borders(frame, border_ratio = 0.343):\n",
    "    height, width, _ = frame.shape\n",
    "    crop_width = int(width * border_ratio)\n",
    "    cropped_frame = frame[:, crop_width:-crop_width]  \n",
    "    return cropped_frame\n",
    "\n",
    "\"\"\" turns compilation into frames and compares the pixel intensities for frames after\n",
    "turning it to grayscale in consecutive order and if it is greater than a certain threshold, \n",
    "func will classify it as a scene change.  \n",
    "\"\"\"\n",
    "def detect_scenes(video_path, threshold):\n",
    "    # initialization\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    scene_changes = []\n",
    "    last_frame = None\n",
    "    frame_index = 0\n",
    "\n",
    "    # handling error if vid can't be opened\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Can't open video at {video_path}\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        cropped_frame = crop_borders(frame)\n",
    "\n",
    "        # convert to BGR, less compute + easy processing pixels\n",
    "        gray_frame = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # compares pixel intensity btwn frames if last frame is present, retrieves diff in values\n",
    "        if last_frame is not None:\n",
    "            diff = cv2.absdiff(gray_frame, last_frame)\n",
    "            mean_diff = diff.mean()\n",
    "\n",
    "            if mean_diff > threshold:\n",
    "                scene_changes.append(frame_index)\n",
    "\n",
    "        last_frame = gray_frame\n",
    "        frame_index += 1\n",
    "\n",
    "    # avoid cv error\n",
    "    cap.release()\n",
    "    return scene_changes\n",
    "\n",
    "\"\"\" takes in previous helper functions: crop_borders & detect_scenes. extracts clips with the side\n",
    "borders cropped out instead of having to manually go into the vid to clip them out. \"\"\"\n",
    "def extract_clips(video_path, scene_changes, output_dir, border_ratio = 0.343):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # handling error if vid can't be opened\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Can't open video at {video_path}\")\n",
    "        return\n",
    "\n",
    "    # encode vid + retrieve dims\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    crop_width = int(width * border_ratio)\n",
    "       \n",
    "    output_width = width - 2 * crop_width\n",
    "    output_height = height\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # append last frame to ensure the final clip is extracted bc detect_scene doesn't account for it\n",
    "    scene_changes.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "    print(\"Starting Clip Extraction:\")\n",
    "    for i in range(len(scene_changes) - 1):\n",
    "        # initialize start and end times based on detect_scenes)\n",
    "        start_frame = scene_changes[i]\n",
    "        end_frame = scene_changes[i + 1]\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clip_{i + 1}.mp4\")\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (output_width, output_height))\n",
    "\n",
    "        #record\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "        for frame_index in range(start_frame, end_frame):\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            cropped_frame = crop_borders(frame, border_ratio)\n",
    "            out.write(cropped_frame)\n",
    "\n",
    "        out.release()\n",
    "        print(f\"Clip {i+1} has been saved to {output_dir}.\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "### ALTER DIRECTORIES TO WHERE THE VIDEO IS LOCATED FOR EACH VID\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"mp4/ratdance.mp4\"  \n",
    "    output_dir = \"ratdance/clips\"  \n",
    "\n",
    "    #tested these values and found that these params were\n",
    "    # best suited for threshold and border_ratio\n",
    "    # most likely threshold can be altered depending on the compilation\n",
    "    # video we're working with but highly unlikely, border_ratio is set          \n",
    "    threshold = 51                 \n",
    "    border_ratio = 0.343              \n",
    "\n",
    "    scene_changes = detect_scenes(video_path, threshold)\n",
    "    print(scene_changes)\n",
    "    extract_clips(video_path, scene_changes, output_dir, border_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping Clips Outside of Avg Clip Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted ratdance/clips/clip_13.mp4 (Duration: 0.30 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_39.mp4 (Duration: 4.20 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_11.mp4 (Duration: 4.27 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_10.mp4 (Duration: 0.03 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_14.mp4 (Duration: 0.03 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_15.mp4 (Duration: 4.44 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_17.mp4 (Duration: 0.77 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_8.mp4 (Duration: 0.03 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_59.mp4 (Duration: 0.47 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_71.mp4 (Duration: 0.57 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_70.mp4 (Duration: 0.53 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_9.mp4 (Duration: 0.07 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_72.mp4 (Duration: 4.94 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_73.mp4 (Duration: 1.07 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_63.mp4 (Duration: 3.54 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_88.mp4 (Duration: 1.94 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_62.mp4 (Duration: 1.67 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_50.mp4 (Duration: 2.37 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_86.mp4 (Duration: 2.14 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_2.mp4 (Duration: 4.47 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_3.mp4 (Duration: 2.24 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_7.mp4 (Duration: 0.17 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_56.mp4 (Duration: 2.27 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_81.mp4 (Duration: 2.20 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_80.mp4 (Duration: 2.30 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_57.mp4 (Duration: 3.00 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_4.mp4 (Duration: 2.24 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_55.mp4 (Duration: 2.04 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_41.mp4 (Duration: 2.47 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_69.mp4 (Duration: 0.67 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_82.mp4 (Duration: 4.30 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_83.mp4 (Duration: 2.20 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_54.mp4 (Duration: 4.64 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_5.mp4 (Duration: 2.17 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_33.mp4 (Duration: 0.77 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_18.mp4 (Duration: 0.57 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_19.mp4 (Duration: 0.60 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_35.mp4 (Duration: 0.40 sec) - below minimum length of 5 sec\n",
      "Deleted ratdance/clips/clip_34.mp4 (Duration: 0.70 sec) - below minimum length of 5 sec\n",
      "Average clip duration: 14.37 seconds\n",
      "Removing clips shorter than 11.37 seconds\n",
      "Deleted ratdance/clips/clip_29.mp4 (Duration: 23.29 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_64.mp4 (Duration: 9.74 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_66.mp4 (Duration: 10.98 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_74.mp4 (Duration: 6.57 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_49.mp4 (Duration: 9.54 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_61.mp4 (Duration: 19.75 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_87.mp4 (Duration: 10.88 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_51.mp4 (Duration: 9.08 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_46.mp4 (Duration: 18.99 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_42.mp4 (Duration: 7.67 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_40.mp4 (Duration: 6.94 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_24.mp4 (Duration: 25.63 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_25.mp4 (Duration: 9.64 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_20.mp4 (Duration: 28.13 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_36.mp4 (Duration: 6.84 sec) - outside deviation\n",
      "Deleted ratdance/clips/clip_22.mp4 (Duration: 26.13 sec) - outside deviation\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\"\"\" Purpose of function is to filter out clips within a time (seconds) deviation based on the average\n",
    "clip length within the folder. This will remove clips whose pixel intensities are so high that the previous\n",
    "helper functions continually clip it frame by frame and also the ending credits clip at the end of the video. \n",
    "Function will remove clip lenths that are less than the min_length (ARBITRARILY SET TO 5 SECONDS) because some clips have\n",
    "constantly changing pixel intensities that surpass the threshold so these chopped clips will be deleted. Then the remaining\n",
    "clips will have their average time length  calculated and a (arbitrary) deviation will be applied to the mean time length\n",
    "and delete videos outside of that frame. \n",
    "FEEL FREE TO ALTER DEVIATION + MIN LENGTH IF IT DOESN'T SUIT CLIPS AFTER MANUALLY INSPECTING \"\"\"\n",
    "# i.e. arbitrary val of 2 based on the \"leave dance\" tiktok dance\n",
    "def filtering_clips(output_dir, fps, deviation=3, min_length=5):\n",
    "    clip_durations = []\n",
    "    clip_paths = []\n",
    "\n",
    "    for clip_name in os.listdir(output_dir):\n",
    "        clip_path = os.path.join(output_dir, clip_name)\n",
    "        \n",
    "        cap = cv2.VideoCapture(clip_path)\n",
    "\n",
    "        # handling error if vid can't be opened \n",
    "        if not cap.isOpened():\n",
    "            print(f\"Could not open {clip_path}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = frame_count / fps  \n",
    "        cap.release()\n",
    "\n",
    "        # FIRST FILTER: REMOVING CLIPS LESS THAN 5 SECONDS LONG\n",
    "        if duration < min_length:\n",
    "            os.remove(clip_path)\n",
    "            print(f\"Deleted {clip_path} (Duration: {duration:.2f} sec) - below minimum length of {min_length} sec\")\n",
    "        else:\n",
    "            # only add clips that meet minimum length req\n",
    "            clip_durations.append(duration)\n",
    "            clip_paths.append(clip_path)\n",
    "\n",
    "    if len(clip_durations) == 0:\n",
    "        print(\"No valid clips found after applying the minimum length filter.\")\n",
    "        return\n",
    "\n",
    "    average_duration = sum(clip_durations) / len(clip_durations)\n",
    "\n",
    "    min_duration = max(0, average_duration - deviation)\n",
    "    max_duration = average_duration + deviation\n",
    "    print(f\"Average clip duration: {average_duration:.2f} seconds\")\n",
    "    print(f\"Removing clips shorter than {min_duration:.2f} seconds\")\n",
    "\n",
    "    for clip_path, duration in zip(clip_paths, clip_durations):\n",
    "        # removes those outside of the deviation range of the avg\n",
    "        # i.e. within 2 seconds of the average\n",
    "        if duration < min_duration or duration > max_duration:\n",
    "            os.remove(clip_path)\n",
    "            print(f\"Deleted {clip_path} (Duration: {duration:.2f} sec) - outside deviation\")\n",
    "\n",
    "### ALTER DIRECTORIES TO WHERE THE VIDEO IS LOCATED FOR EACH VID\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"mp4/ratdance.mp4\"  \n",
    "    output_dir = \"ratdance/clips\"            \n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    filtering_clips(output_dir, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\"\"\"Purpose of function is to divide the clips into three sets: training, validation, and testing. \n",
    "params for the ratios are set to 60:20:20 but FEEL FREE TO CHANGE THE VALS. \n",
    "Also, split is done randomly as welln. \n",
    "\"\"\"\n",
    "def split_dataset(input_dir, output_dir, train_ratio, val_ratio, test_ratio):\n",
    "    all_entries = os.listdir(input_dir)\n",
    "    clips = []\n",
    "    for clip in all_entries:\n",
    "        file_path = os.path.join(input_dir, clip)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            clips.append(clip)\n",
    "        \n",
    "    # RANDOMDMDMDMDMMDMMM\n",
    "    # random.seed(42)\n",
    "    random.shuffle(clips)\n",
    "    \n",
    "    total = len(clips)\n",
    "\n",
    "    train_count = int(total * train_ratio)\n",
    "    val_count = int(total * val_ratio)\n",
    "    \n",
    "    train_files = clips[:train_count]\n",
    "    val_files = clips[train_count:train_count + val_count]\n",
    "    test_files = clips[train_count + val_count:]\n",
    "    \n",
    "    train_dir = os.path.join(output_dir, \"train\")\n",
    "    val_dir = os.path.join(output_dir, \"val\")\n",
    "    test_dir = os.path.join(output_dir, \"test\")\n",
    "    \n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # trainfiles\n",
    "    for clip in train_files:\n",
    "        src_path = os.path.join(input_dir, clip)\n",
    "        dst_path = os.path.join(train_dir, clip)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # val files\n",
    "    for clip in val_files:\n",
    "        src_path = os.path.join(input_dir, clip)\n",
    "        dst_path = os.path.join(val_dir, clip)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # test files\n",
    "    for clip in test_files:\n",
    "        src_path = os.path.join(input_dir, clip)\n",
    "        dst_path = os.path.join(test_dir, clip)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    #deeleting files in clip folder\n",
    "    shutil.rmtree(input_dir)\n",
    "    \n",
    "### ALTER DIRECTORIES TO WHERE THE VIDEO IS LOCATED FOR EACH VID\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = \"ratdance/clips\"  \n",
    "    output_dir = \"ratdance/\"  \n",
    "    split_dataset(input_dir, output_dir, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2)\n",
    "    print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting negative control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 5 clips from mp4/savagelove.mp4\n",
      "Saved: negative_control/clips/savagelove_clip_1.mp4 (Duration: 15.13 sec)\n",
      "Saved: negative_control/clips/savagelove_clip_2.mp4 (Duration: 15.07 sec)\n",
      "Saved: negative_control/clips/savagelove_clip_3.mp4 (Duration: 15.03 sec)\n",
      "Saved: negative_control/clips/savagelove_clip_4.mp4 (Duration: 15.13 sec)\n",
      "Saved: negative_control/clips/savagelove_clip_5.mp4 (Duration: 15.13 sec)\n",
      "Extracting 5 clips from mp4/fendi&prada.mp4\n",
      "Saved: negative_control/clips/fendi&prada_clip_1.mp4 (Duration: 14.55 sec)\n",
      "Saved: negative_control/clips/fendi&prada_clip_2.mp4 (Duration: 14.58 sec)\n",
      "Saved: negative_control/clips/fendi&prada_clip_3.mp4 (Duration: 14.55 sec)\n",
      "Saved: negative_control/clips/fendi&prada_clip_4.mp4 (Duration: 14.61 sec)\n",
      "Saved: negative_control/clips/fendi&prada_clip_5.mp4 (Duration: 14.58 sec)\n",
      "Extracting 5 clips from mp4/facelikeamodel.mp4\n",
      "Saved: negative_control/clips/facelikeamodel_clip_1.mp4 (Duration: 15.07 sec)\n",
      "Saved: negative_control/clips/facelikeamodel_clip_2.mp4 (Duration: 11.40 sec)\n",
      "Saved: negative_control/clips/facelikeamodel_clip_3.mp4 (Duration: 14.23 sec)\n",
      "Saved: negative_control/clips/facelikeamodel_clip_4.mp4 (Duration: 15.07 sec)\n",
      "Saved: negative_control/clips/facelikeamodel_clip_5.mp4 (Duration: 12.70 sec)\n",
      "Extracting 5 clips from mp4/candydance.mp4\n",
      "Saved: negative_control/clips/candydance_clip_1.mp4 (Duration: 6.93 sec)\n",
      "Saved: negative_control/clips/candydance_clip_2.mp4 (Duration: 15.07 sec)\n",
      "Saved: negative_control/clips/candydance_clip_3.mp4 (Duration: 9.20 sec)\n",
      "Saved: negative_control/clips/candydance_clip_4.mp4 (Duration: 8.93 sec)\n",
      "Saved: negative_control/clips/candydance_clip_5.mp4 (Duration: 15.07 sec)\n",
      "Extracting 5 clips from mp4/ohnana.mp4\n",
      "Saved: negative_control/clips/ohnana_clip_1.mp4 (Duration: 13.60 sec)\n",
      "Saved: negative_control/clips/ohnana_clip_2.mp4 (Duration: 15.00 sec)\n",
      "Saved: negative_control/clips/ohnana_clip_3.mp4 (Duration: 13.63 sec)\n",
      "Saved: negative_control/clips/ohnana_clip_4.mp4 (Duration: 14.90 sec)\n",
      "Saved: negative_control/clips/ohnana_clip_5.mp4 (Duration: 13.60 sec)\n",
      "Extracting 5 clips from mp4/leavedance.mp4\n",
      "Saved: negative_control/clips/leavedance_clip_1.mp4 (Duration: 15.07 sec)\n",
      "Saved: negative_control/clips/leavedance_clip_2.mp4 (Duration: 13.03 sec)\n",
      "Saved: negative_control/clips/leavedance_clip_3.mp4 (Duration: 15.10 sec)\n",
      "Saved: negative_control/clips/leavedance_clip_4.mp4 (Duration: 9.90 sec)\n",
      "Saved: negative_control/clips/leavedance_clip_5.mp4 (Duration: 12.33 sec)\n",
      "Extracting 5 clips from mp4/newjeans.mp4\n",
      "Saved: negative_control/clips/newjeans_clip_1.mp4 (Duration: 19.52 sec)\n",
      "Saved: negative_control/clips/newjeans_clip_2.mp4 (Duration: 33.13 sec)\n",
      "Saved: negative_control/clips/newjeans_clip_3.mp4 (Duration: 19.39 sec)\n",
      "Saved: negative_control/clips/newjeans_clip_4.mp4 (Duration: 13.55 sec)\n",
      "Saved: negative_control/clips/newjeans_clip_5.mp4 (Duration: 16.75 sec)\n",
      "negative control dataset DONE!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "\n",
    "\"\"\" purpose of this function is to crop the borders equally on both sides. Tested \n",
    "different border_ratio param values and found that 0.343 best suited for \n",
    "the the compilations videos in the dataset.\"\"\"\n",
    "def crop_borders(frame, border_ratio = 0.343):\n",
    "    height, width, _ = frame.shape\n",
    "    crop_width = int(width * border_ratio)\n",
    "    cropped_frame = frame[:, crop_width:-crop_width]  \n",
    "    return cropped_frame\n",
    "\n",
    "\"\"\" turns compilation into frames and compares the pixel intensities for frames after\n",
    "turning it to grayscale in consecutive order and if it is greater than a certain threshold, \n",
    "func will classify it as a scene change.  \n",
    "\"\"\"\n",
    "def detect_scenes(video_path, threshold, border_ratio = 0.343):\n",
    "    # initialization\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    scene_changes = []\n",
    "    last_frame = None\n",
    "    frame_index = 0\n",
    "\n",
    "    # handling error if vid can't be opened\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Can't open video at {video_path}\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        cropped_frame = crop_borders(frame, border_ratio)\n",
    "\n",
    "        # convert to BGR, less compute + easy processing pixels\n",
    "        gray_frame = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # compares pixel intensity btwn frames if last frame is present, retrieves diff in values\n",
    "        if last_frame is not None:\n",
    "            diff = cv2.absdiff(gray_frame, last_frame)\n",
    "            mean_diff = diff.mean()\n",
    "\n",
    "            if mean_diff > threshold:\n",
    "                scene_changes.append(frame_index)\n",
    "\n",
    "        last_frame = gray_frame\n",
    "        frame_index += 1\n",
    "\n",
    "    # avoid cv error\n",
    "    cap.release()\n",
    "    return scene_changes\n",
    "\n",
    "\"\"\" takes in previous helper functions: crop_borders & detect_scenes. extracts clips with the side\n",
    "borders cropped out instead of having to manually go into the vid to clip them out. \n",
    "added in num_clips and min_length to specify how many clips to extract from each vid in mp4 folder\n",
    "min_length is just an arbitrary number set to 5 seconds to trim off those that have their pixel intensities\n",
    "change every frame and it messes up the alg. the function also extracts clips from every pair of scene_changes\n",
    "so long as it meets the min_length threshold & selects up to num_clips pairs randomly. \"\"\"\n",
    "def extract_clips(video_path, scene_changes, output_dir, num_clips, border_ratio = 0.343, min_length = 5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # handling error if vid can't be opened\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Can't open video at {video_path}\")\n",
    "        return\n",
    "\n",
    "    # encode vid + retrieve dims\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    crop_width = int(width * border_ratio)\n",
    "       \n",
    "    output_width = width - 2 * crop_width\n",
    "    output_height = height\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # append last frame to ensure the final clip is extracted bc detect_scene doesn't account for it\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    scene_changes.append(total_frames)\n",
    "\n",
    "    # clip pairs from consecutive scene changes that are at least min_length secs long\n",
    "    min_frames = int(math.ceil(fps * min_length))\n",
    "    clip_pairs = []\n",
    "    for i in range(len(scene_changes)-1):\n",
    "        start_frame = scene_changes[i]\n",
    "        end_frame = scene_changes[i+1]\n",
    "        if (end_frame - start_frame) >= min_frames:\n",
    "            clip_pairs.append((start_frame, end_frame))\n",
    "\n",
    "    if not clip_pairs:\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # RANDOMLY SELECT UP TO NUM_CLIPS PAIRS\n",
    "    selected_pairs = random.sample(clip_pairs, min(num_clips, len(clip_pairs)))\n",
    "    print(f\"Extracting {len(selected_pairs)} clips from {video_path}\")\n",
    "    for i, (start_frame, end_frame) in enumerate(selected_pairs):\n",
    "        clip_filename = f\"{os.path.splitext(os.path.basename(video_path))[0]}_clip_{i+1}.mp4\"\n",
    "        output_path = os.path.join(output_dir, clip_filename)\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (output_width, output_height))\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "        for frame_index in range(start_frame, end_frame):\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            cropped_frame = crop_borders(frame, border_ratio)\n",
    "            out.write(cropped_frame)\n",
    "\n",
    "        out.release()\n",
    "        actual_duration = (end_frame - start_frame) / fps\n",
    "        print(f\"Saved: {output_path} (Duration: {actual_duration:.2f} sec)\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\"\"\" Purpose of function is to filter out clips within a time (seconds) deviation based on the average\n",
    "clip length within the folder. This will remove clips whose pixel intensities are so high that the previous\n",
    "helper functions continually clip it frame by frame and also the ending credits clip at the end of the video. \n",
    "Function will remove clip lenths that are less than the min_length (ARBITRARILY SET TO 5 SECONDS) because some clips have\n",
    "constantly changing pixel intensities that surpass the threshold so these chopped clips will be deleted. Then the remaining\n",
    "clips will have their average time length calculated and a (arbitrary) deviation will be applied to the mean time length\n",
    "and delete videos outside of that frame.\n",
    "FEEL FREE TO ALTER DEVIATION + MIN LENGTH IF IT DOESN'T SUIT CLIPS AFTER MANUALLY INSPECTING \n",
    "\n",
    "changed filtering function to now group clips by their original name (the part before '_clip_')\n",
    "so that filtering is done based on dance, I also added print statements just so i can see if the loops are\n",
    "running as intended lol (was gonna remove them but i think they look nice)\"\"\"\n",
    "def filtering_clips(output_dir, fps, deviation=3, min_length=5):\n",
    "    # group clips by the original video name (the part before '_clip_')\n",
    "    groups = {}\n",
    "    for clip_name in os.listdir(output_dir):\n",
    "        if clip_name.endswith('.mp4'):\n",
    "            group_key = clip_name.split(\"_clip_\")[0]\n",
    "            groups.setdefault(group_key, []).append(clip_name)\n",
    "    \n",
    "    # process each group/dance separately\n",
    "    for group_key, clip_names in groups.items():\n",
    "        clip_durations = []\n",
    "        clip_paths = []\n",
    "\n",
    "        # measures durations for all clips in group\n",
    "        for clip_name in clip_names:\n",
    "            clip_path = os.path.join(output_dir, clip_name)\n",
    "            cap = cv2.VideoCapture(clip_path)\n",
    "            # handling error if vid can't be opened \n",
    "            if not cap.isOpened():\n",
    "                print(f\"Could not open {clip_path}, skipping.\")\n",
    "                continue\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            duration = frame_count / fps\n",
    "            cap.release()\n",
    "\n",
    "            # FIRST FILTER: REMOVING CLIPS LESS THAN min_length SECONDS LONG\n",
    "            if duration < min_length:\n",
    "                os.remove(clip_path)\n",
    "                print(f\"Deleted {clip_path} (Duration: {duration:.2f} sec), below {min_length}s\")\n",
    "            else:\n",
    "                clip_durations.append(duration)\n",
    "                clip_paths.append(clip_path)\n",
    "        \n",
    "        if len(clip_durations) == 0:\n",
    "            print(f\"No valid clips for {group_key} after min_length filter\")\n",
    "            continue\n",
    "\n",
    "        avg_duration = sum(clip_durations) / len(clip_durations)\n",
    "        min_duration = max(0, avg_duration - deviation)\n",
    "        max_duration = avg_duration + deviation\n",
    "        print(f\"{group_key}\")\n",
    "        print(f\"Avg Clip Duration = {avg_duration:.2f}s\")\n",
    "        # print(f\"Range: ({min_duration:.2f}s - {max_duration:.2f}s)\")\n",
    "        print(f\"Removing clips outside dev ({min_duration:.2f}s - {max_duration:.2f}s)\")\n",
    "\n",
    "        # remove clips outside the dev range for this group\n",
    "        for clip_path, duration in zip(clip_paths, clip_durations):\n",
    "            if duration < min_duration or duration > max_duration:\n",
    "                os.remove(clip_path)\n",
    "                print(f\"Deleted {clip_path} (Duration: {duration:.2f}s) - outside deviation\")\n",
    "\n",
    "\"\"\"Purpose of function is to divide the clips into three sets: training, validation, and testing. \n",
    "params for the ratios are set to 60:20:20 but FEEL FREE TO CHANGE THE VALS. \n",
    "Also, split is done randomly as well. looks more mp4 files specifically as an edge case \n",
    "\"\"\"\n",
    "def split_dataset(input_dir, output_dir, train_ratio, val_ratio, test_ratio):\n",
    "    all_entries = os.listdir(input_dir)\n",
    "    clips = []\n",
    "    for clip in all_entries:\n",
    "        file_path = os.path.join(input_dir, clip)\n",
    "        if os.path.isfile(file_path):\n",
    "            clips.append(clip)\n",
    "        \n",
    "    # RANDOMDMDMDMDMMDMMM\n",
    "    # random.seed(42)\n",
    "    random.shuffle(clips)\n",
    "    \n",
    "    total = len(clips)\n",
    "    train_count = int(total * train_ratio)\n",
    "    val_count = int(total * val_ratio)\n",
    "    \n",
    "    train_files = clips[:train_count]\n",
    "    val_files = clips[train_count:train_count + val_count]\n",
    "    test_files = clips[train_count + val_count:]\n",
    "    \n",
    "    train_dir = os.path.join(output_dir, \"train\")\n",
    "    val_dir = os.path.join(output_dir, \"val\")\n",
    "    test_dir = os.path.join(output_dir, \"test\")\n",
    "    \n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # trainfiles\n",
    "    for clip in train_files:\n",
    "        src_path = os.path.join(input_dir, clip)\n",
    "        dst_path = os.path.join(train_dir, clip)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # val files\n",
    "    for clip in val_files:\n",
    "        src_path = os.path.join(input_dir, clip)\n",
    "        dst_path = os.path.join(val_dir, clip)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # test files\n",
    "    for clip in test_files:\n",
    "        src_path = os.path.join(input_dir, clip)\n",
    "        dst_path = os.path.join(test_dir, clip)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    # deeleting files in clip folder\n",
    "    shutil.rmtree(input_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_folder = \"mp4\"                   \n",
    "    output_folder = \"negative_control\"    \n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    clips_dir = os.path.join(output_folder, \"clips\")\n",
    "    os.makedirs(clips_dir, exist_ok=True)\n",
    "\n",
    "    threshold = 51                        \n",
    "    border_ratio = 0.343\n",
    "\n",
    "    # ALTER VAL FOR MORE CLIPS PER VID\n",
    "    num_clips_per_video = 5          \n",
    "    # ALTER VAL FOR MORE CLIPS PER VID\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.mp4'):\n",
    "            video_path = os.path.join(input_folder, filename)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            cap.release()\n",
    "\n",
    "            scene_changes = detect_scenes(video_path, threshold, border_ratio)\n",
    "            if scene_changes:\n",
    "                extract_clips(video_path, scene_changes, clips_dir, num_clips_per_video, border_ratio, min_length=5)\n",
    "\n",
    "    split_dataset(clips_dir, output_folder, train_ratio=0.6, val_ratio= 0.2, test_ratio=0.2)\n",
    "    print(\"negative control dataset DONE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
